{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing pandas and numpy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Dataframe\n",
    "df = pd.read_csv(r'C:\\Users\\acer\\Desktop\\python practice\\UPDATED-NLP-COURSE\\TextFiles\\smsspamcollection.tsv',sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>length</th>\n",
       "      <th>punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message  length  punct\n",
       "0   ham  Go until jurong point, crazy.. Available only ...     111      9\n",
       "1   ham                      Ok lar... Joking wif u oni...      29      6\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...     155      6\n",
       "3   ham  U dun say so early hor... U c already then say...      49      6\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...      61      2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the first five rows of information\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label      0\n",
       "message    0\n",
       "length     0\n",
       "punct      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the null in the dataframe\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5572"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No of observations in the dataframe\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham', 'spam'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unique values\n",
    "df['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No.of counts of ham and spam\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.406317300789663"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# percentage of ham and spam counts\n",
    "747/(4825+747)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### only 13.4% are spam observations in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5572.000000\n",
       "mean       80.489950\n",
       "std        59.942907\n",
       "min         2.000000\n",
       "25%        36.000000\n",
       "50%        62.000000\n",
       "75%       122.000000\n",
       "max       910.000000\n",
       "Name: length, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.xscale('log')\n",
    "bins = 1.15**(np.arange(0,50))\n",
    "plt.hist(df[df['label'] == 'ham']['length'], bins = bins, alpha = 0.8)\n",
    "plt.hist(df[df['label'] == 'spam']['length'], bins = bins, alpha = 0.8)\n",
    "plt.legend(('ham','spam'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigger Range of values is more likely to be spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5572.000000\n",
       "mean        4.177495\n",
       "std         4.623919\n",
       "min         0.000000\n",
       "25%         2.000000\n",
       "50%         3.000000\n",
       "75%         6.000000\n",
       "max       133.000000\n",
       "Name: punct, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['punct'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAARJElEQVR4nO3df5CdVX3H8fc3PyBghWgSGdxFNozRRnInomsSamgHw8REGsMAmUJFE82Q1iFRoEqg0xkc/adqxyjYSQnGGmcyGAtMQ4qlVVAqM4Bs+OEmpjYRUriGwhpDmgLRJJz+sc+GTdjN3s3eZ+/ek/drJrPPj/Oc/V7O3M8ezj732UgpIUnKy6hGFyBJqj/DXZIyZLhLUoYMd0nKkOEuSRky3CUpQ2MaXQDAxIkTU1tbW6PLkKSmsnnz5t+klCb1dW5EhHtbWxsdHR2NLkOSmkpE/Hd/51yWkaQMGe6SlCHDXZIyNCLW3CWpFgcOHKBarbJ///5GlzKsxo0bR2trK2PHjq35GsNdUtOoVqu8+c1vpq2tjYhodDnDIqXE7t27qVarTJ48uebrXJaR1DT279/PhAkTTphgB4gIJkyYMOj/WzHcJTWVEynYexzPazbcJalGO3fuZNq0aY0uoyauufdjwa0PldLvphWzS+lXOhHV+32a0/vTmbskDcKhQ4e4+uqrOffcc5k7dy6vvvoqt99+Ox/4wAeYPn06l112Ga+88goAS5Ys4dOf/jQXXngh55xzDg8++CCf+tSnmDp1KkuWLCm1TsNdkgZh+/btXHPNNWzdupXx48dz1113cemll/LYY4/x1FNPMXXqVNauXXu4/Z49e3jggQdYtWoVCxYs4LrrrmPr1q10dnby5JNPllan4S5JgzB58mTe+973AvD+97+fnTt3smXLFi644AIqlQrr169n69ath9svWLCAiKBSqXDGGWdQqVQYNWoU5557Ljt37iytTsNdkgbh5JNPPrw9evRoDh48yJIlS/jmN79JZ2cnN9988xG3Lfa0HzVq1BHXjho1ioMHD5ZWp+EuSUO0b98+zjzzTA4cOMD69esbXQ7g3TKSNGRf+tKXmDlzJmeffTaVSoV9+/Y1uiQipdToGmhvb08j7Xnu3gopjTzbtm1j6tSpjS6jIfp67RGxOaXU3ld7l2UkKUOGuyRlqOnX3MtaPpGkZubMXZIyZLhLUoYMd0nKkOEuSRlq+l+oSjqB3fYn9e3vLx6sb38N5Mxdkmr08ssvc/HFFzN9+nSmTZvGhg0baGtrY+XKlcyYMYMZM2awY8cOADZt2sTMmTM577zzuOiii3jhhRcA+MIXvsDixYuZO3cubW1t3H333dxwww1UKhXmzZvHgQMH6lKr4S5JNbrvvvt4+9vfzlNPPcWWLVuYN28eAKeddho/+9nPWL58Oddeey0As2fP5pFHHuGJJ57giiuu4Ctf+crhfn71q19x7733snHjRq666iouvPBCOjs7OeWUU7j33nvrUqvhLkk1qlQq/OhHP2LlypX89Kc/5fTTTwfgyiuvPPz14YcfBqBarfLhD3+YSqXCV7/61SMeAzx//nzGjh1LpVLh0KFDh39IVCqVuj0G2HCXpBq9613vYvPmzVQqFW666Sa++MUvAkf+Aeue7RUrVrB8+XI6Ozu57bbb+n0M8NixYw9fU8/HABvuklSjXbt2ceqpp3LVVVfxuc99jscffxyADRs2HP56/vnnA7B3715aWloAWLdu3bDX6t0yklSjzs5OPv/5zx+eca9evZrLL7+c3/3ud8ycOZPXXnuNO+64A+j+xemiRYtoaWlh1qxZPPPMM8Naa9M/8rfZni3jI3+l4zcSH/nb1tZGR0cHEydOLPX7+MhfSZLLMpI0FGX+keuhqGnmHhHXRcTWiNgSEXdExLiImBwRj0bE9ojYEBEnFW1PLvZ3FOfbynwBkqQ3GjDcI6IF+AzQnlKaBowGrgC+DKxKKU0B9gBLi0uWAntSSu8EVhXtJKkuRsLvCYfb8bzmWtfcxwCnRMQY4FTgeeBDwJ3F+XXAJcX2wmKf4vyc6H0TqCQdp3HjxrF79+4TKuBTSuzevZtx48YN6roB19xTSr+OiL8DngVeBf4d2Ay8lFLqudu+CrQU2y3Ac8W1ByNiLzAB+M2gKpOko7S2tlKtVunq6mp0KcNq3LhxtLa2DuqaAcM9It5C92x8MvAS8E/A/D6a9vwo7WuW/oYfsxGxDFgG8I53vKPGciWdyMaOHcvkyZMbXUZTqGVZ5iLgmZRSV0rpAHA38EfA+GKZBqAV2FVsV4GzAIrzpwO/PbrTlNKalFJ7Sql90qRJQ3wZkqTeagn3Z4FZEXFqsXY+B/gF8GPg8qLNYmBjsX1PsU9x/oF0Ii2QSdIIMGC4p5QepfsXo48DncU1a4CVwPURsYPuNfW1xSVrgQnF8euBG0uoW5J0DDV9iCmldDNw81GHnwZm9NF2P7Bo6KVJko6Xjx+QpAwZ7pKUIZ8tk4kyno7pEyyl5uXMXZIyZLhLUoYMd0nKkOEuSRky3CUpQ4a7JGXIcJekDBnukpQhw12SMuQnVIdZGZ8klaSjOXOXpAwZ7pKUIcNdkjJkuEtShgx3ScqQ4S5JGTLcJSlDhrskZchwl6QMGe6SlCHDXZIyZLhLUoYMd0nKkOEuSRky3CUpQ4a7JGXIcJekDBnukpQhw12SMmS4S1KGDHdJypDhLkkZMtwlKUM1hXtEjI+IOyPiPyNiW0ScHxFvjYgfRsT24utbirYREbdExI6I+HlEvK/clyBJOlqtM/dvAPellP4QmA5sA24E7k8pTQHuL/YB5gNTin/LgNV1rViSNKABwz0iTgP+GFgLkFL6fUrpJWAhsK5otg64pNheCHw3dXsEGB8RZ9a9cklSv2qZuZ8DdAH/GBFPRMS3IuJNwBkppecBiq9vK9q3AM/1ur5aHDtCRCyLiI6I6Ojq6hrSi5AkHamWcB8DvA9YnVI6D3iZ15dg+hJ9HEtvOJDSmpRSe0qpfdKkSTUVK0mqTS3hXgWqKaVHi/076Q77F3qWW4qvL/Zqf1av61uBXfUpV5JUiwHDPaX0P8BzEfHu4tAc4BfAPcDi4thiYGOxfQ/wieKumVnA3p7lG0nS8BhTY7sVwPqIOAl4Gvgk3T8Yvh8RS4FngUVF2x8AHwF2AK8UbSVJw6imcE8pPQm093FqTh9tE3DNEOuSJA2Bn1CVpAwZ7pKUIcNdkjJkuEtShgx3ScqQ4S5JGTLcJSlDhrskZchwl6QMGe6SlCHDXZIyZLhLUoYMd0nKkOEuSRky3CUpQ4a7JGXIcJekDBnukpQhw12SMmS4S1KGDHdJypDhLkkZMtwlKUNjGl2ARq4Ftz5USr+bVswupV9Jr3PmLkkZMtwlKUOGuyRlyHCXpAwZ7pKUIcNdkjJkuEtShgx3ScqQ4S5JGTLcJSlDhrskZajmcI+I0RHxRET8S7E/OSIejYjtEbEhIk4qjp9c7O8ozreVU7okqT+Dmbl/FtjWa//LwKqU0hRgD7C0OL4U2JNSeiewqmgnSRpGNYV7RLQCFwPfKvYD+BBwZ9FkHXBJsb2w2Kc4P6doL0kaJrXO3L8O3AC8VuxPAF5KKR0s9qtAS7HdAjwHUJzfW7SXJA2TAcM9Iv4UeDGltLn34T6aphrO9e53WUR0RERHV1dXTcVKkmpTy8z9g8BHI2In8D26l2O+DoyPiJ4/9tEK7Cq2q8BZAMX504HfHt1pSmlNSqk9pdQ+adKkIb0ISdKRBgz3lNJNKaXWlFIbcAXwQErpY8CPgcuLZouBjcX2PcU+xfkHUkpvmLlLksozlPvcVwLXR8QOutfU1xbH1wITiuPXAzcOrURJ0mAN6m+oppR+Avyk2H4amNFHm/3AojrUJkk6Tn5CVZIyZLhLUoYMd0nKkOEuSRky3CUpQ4a7JGVoULdCSvWw4NaHSul304rZpfQrNSNn7pKUIcNdkjJkuEtShgx3ScqQ4S5JGTLcJSlDhrskZchwl6QMGe6SlCHDXZIyZLhLUoYMd0nKkOEuSRky3CUpQ4a7JGXIcJekDBnukpQhw12SMmS4S1KGDHdJypDhLkkZMtwlKUOGuyRlyHCXpAwZ7pKUIcNdkjJkuEtShgx3ScqQ4S5JGRow3CPirIj4cURsi4itEfHZ4vhbI+KHEbG9+PqW4nhExC0RsSMifh4R7yv7RUiSjlTLzP0g8FcppanALOCaiHgPcCNwf0ppCnB/sQ8wH5hS/FsGrK571ZKkYxow3FNKz6eUHi+29wHbgBZgIbCuaLYOuKTYXgh8N3V7BBgfEWfWvXJJUr8GteYeEW3AecCjwBkppeeh+wcA8LaiWQvwXK/LqsWxo/taFhEdEdHR1dU1+MolSf2qOdwj4g+Au4BrU0r/e6ymfRxLbziQ0pqUUntKqX3SpEm1liFJqkFN4R4RY+kO9vUppbuLwy/0LLcUX18sjleBs3pd3grsqk+5kqRa1HK3TABrgW0ppa/1OnUPsLjYXgxs7HX8E8VdM7OAvT3LN5Kk4TGmhjYfBD4OdEbEk8Wxvwb+Fvh+RCwFngUWFed+AHwE2AG8AnyyrhVLkgY0YLinlB6i73V0gDl9tE/ANUOsS5I0BLXM3KWmsODWh+re56YVs+vepzQcfPyAJGXIcJekDLkso3597aXPltLv9eO/UUq/kl5nuGvY+UNDKp/LMpKUIcNdkjLkskwmylrqkNScnLlLUoYMd0nKkOEuSRky3CUpQ4a7JGXIu2WGmXe1SBoOztwlKUOGuyRlyHCXpAwZ7pKUIcNdkjJkuEtShgx3ScqQ4S5JGTLcJSlDfkK1H36SVFIzc+YuSRky3CUpQ4a7JGXIcJekDPkLVekYFtz6UCn9bloxu5R+pR7O3CUpQ87clY0ybl+9fvw36t6nNBycuUtShgx3ScpQ0y/L+ElSSXojZ+6SlKGmn7lLzchbLFW2UmbuETEvIn4ZETsi4sYyvockqX91D/eIGA38PTAfeA9wZUS8p97fR5LUvzKWZWYAO1JKTwNExPeAhcAvSvheUqnK+oV9WffPu9yjHmWEewvwXK/9KjDz6EYRsQxYVuz+X0T8stg+HdjbT999nZsI/Oa4qy3HsV5DI/sd7PW1tB9qm/7O9Xc8k/G+oKR+j/vaY7aPz9Tc7/GMdX/nMhnrUvs9u98zKaW6/gMWAd/qtf9x4NZBXL9mMOeAjnq/hjr8N+j3NTSy38FeX0v7obbp79wxjjveDRrrWtodz1j3d86xHtq/Mn6hWgXO6rXfCuwaxPWbjvPcSFJWnUPtd7DX19J+qG36O9csYw0jc7zLGOta2h3v+7dZxnskjnWfovipUb8OI8YA/wXMAX4NPAb8eUppa12/0evfryOl1F5G3xp5HO8Th2M9NHVfc08pHYyI5cC/AaOBb5cV7IU1JfatkcfxPnE41kNQ95m7JKnxfPyAJGXIcJekDBnukpSh7MI9It4UEesi4vaI+Fij61F5IuKciFgbEXc2uhaVLyIuKd7XGyNibqPrGemaItwj4tsR8WJEbDnqeF8PKLsUuDOldDXw0WEvVkMymLFOKT2dUlramEpVD4Mc738u3tdLgD9rQLlNpSnCHfgOMK/3gWM8oKyV1x9/cGgYa1R9fIfax1rN7zsMfrz/pjivY2iKcE8p/Qfw26MOH35AWUrp90DPA8qqdAc8NMnr0+sGOdZqcoMZ7+j2ZeBfU0qPD3etzaaZw6+vB5S1AHcDl0XEaprnI806tj7HOiImRMQ/AOdFxE2NKU0l6O+9vQK4CLg8Iv6yEYU1k2b+S0zRx7GUUnoZ+ORwF6NS9TfWuwHf5Pnpb7xvAW4Z7mKaVTPP3If6gDI1D8f6xOJ410Ezh/tjwJSImBwRJwFXAPc0uCaVw7E+sTjeddAU4R4RdwAPA++OiGpELE0pHQR6HlC2Dfh+yQ8o0zBwrE8sjnd5fHCYJGWoKWbukqTBMdwlKUOGuyRlyHCXpAwZ7pKUIcNdkjJkuEtShgx3ScqQ4S5JGfp/0DKY4fCtzG0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xscale('log')\n",
    "bins = 1.5**(np.arange(0,15))\n",
    "plt.hist(df[df['label'] == 'ham']['punct'], bins = bins, alpha = 0.8)\n",
    "plt.hist(df[df['label'] == 'spam']['punct'], bins = bins, alpha = 0.8)\n",
    "plt.legend(('ham','spam'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By this data. we are not getting information to select spam or ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape:(3733, 2)\n",
      "Testting shape:(1839, 2)\n"
     ]
    }
   ],
   "source": [
    "# creating the train and test data sets\n",
    "\n",
    "x = df[['length','punct']]\n",
    "y = df['label']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.33, random_state = 42)\n",
    "\n",
    "print(f'Training shape:{x_train.shape}')\n",
    "print(f'Testting shape:{x_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion Matrix\n",
      "       ham  spam\n",
      "ham   1547    46\n",
      "spam   241     5\n",
      "\n",
      "\n",
      "\n",
      " Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.87      0.97      0.92      1593\n",
      "        spam       0.10      0.02      0.03       246\n",
      "\n",
      "    accuracy                           0.84      1839\n",
      "   macro avg       0.48      0.50      0.47      1839\n",
      "weighted avg       0.76      0.84      0.80      1839\n",
      "\n",
      "\n",
      "\n",
      "accuracy score : 0.843936922240348\n"
     ]
    }
   ],
   "source": [
    "# Applying the Logistic regression for the classification\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_model = LogisticRegression()\n",
    "\n",
    "lr_model.fit(x_train,y_train)\n",
    "\n",
    "# getting the Accuracy of the Model\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "# performing the prediction\n",
    "\n",
    "predictions = lr_model.predict(x_test)\n",
    "\n",
    "# printing the confusion matrix\n",
    "print('confusion Matrix')\n",
    "print(pd.DataFrame(metrics.confusion_matrix(y_test, predictions), index = ['ham', 'spam'], columns = ['ham', 'spam']))\n",
    "\n",
    "# printing the recall and precision \n",
    "print('\\n\\n')\n",
    "print(' Classification Report')\n",
    "print(metrics.classification_report(y_test, predictions))\n",
    "\n",
    "# getting the accuracy of the model\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print(f'accuracy score : {metrics.accuracy_score(y_test,predictions)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here True positives are only 5 and misclassfying the 245(False positive) as ham \n",
    "\n",
    "### Here accuracy score is high. Still model is worse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion Matrix\n",
      "       ham  spam\n",
      "ham   1583    10\n",
      "spam   246     0\n",
      "\n",
      "\n",
      "\n",
      " Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.87      0.99      0.93      1593\n",
      "        spam       0.00      0.00      0.00       246\n",
      "\n",
      "    accuracy                           0.86      1839\n",
      "   macro avg       0.43      0.50      0.46      1839\n",
      "weighted avg       0.75      0.86      0.80      1839\n",
      "\n",
      "\n",
      "\n",
      "accuracy score : 0.8607939097335509\n"
     ]
    }
   ],
   "source": [
    "# Applying the naive Bayes for the classification\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "nb_model.fit(x_train,y_train)\n",
    "\n",
    "\n",
    "\n",
    "# performing the prediction\n",
    "\n",
    "predictions = nb_model.predict(x_test)\n",
    "\n",
    "# printing the confusion matrix\n",
    "print('confusion Matrix')\n",
    "print(pd.DataFrame(metrics.confusion_matrix(y_test, predictions), index = ['ham', 'spam'], columns = ['ham', 'spam']))\n",
    "\n",
    "# printing the recall and precision \n",
    "print('\\n\\n')\n",
    "print(' Classification Report')\n",
    "print(metrics.classification_report(y_test, predictions))\n",
    "\n",
    "# getting the accuracy of the model\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print(f'accuracy score : {metrics.accuracy_score(y_test,predictions)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Baye's Model is worse than the Logistic Regression. We are classying all of the observations of spam as Ham.\n",
    "## Here Recall and F1 score is Zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion Matrix\n",
      "       ham  spam\n",
      "ham   1555    38\n",
      "spam   193    53\n",
      "\n",
      "\n",
      "\n",
      " Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.89      0.98      0.93      1593\n",
      "        spam       0.58      0.22      0.31       246\n",
      "\n",
      "    accuracy                           0.87      1839\n",
      "   macro avg       0.74      0.60      0.62      1839\n",
      "weighted avg       0.85      0.87      0.85      1839\n",
      "\n",
      "\n",
      "\n",
      "accuracy score : 0.8743882544861338\n"
     ]
    }
   ],
   "source": [
    "# Applying the Support vector Machines for the classification\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svc_model = SVC()\n",
    "\n",
    "svc_model.fit(x_train,y_train)\n",
    "\n",
    "\n",
    "\n",
    "# performing the prediction\n",
    "\n",
    "predictions = svc_model.predict(x_test)\n",
    "\n",
    "# printing the confusion matrix\n",
    "print('confusion Matrix')\n",
    "print(pd.DataFrame(metrics.confusion_matrix(y_test, predictions), index = ['ham', 'spam'], columns = ['ham', 'spam']))\n",
    "\n",
    "# printing the recall and precision \n",
    "print('\\n\\n')\n",
    "print(' Classification Report')\n",
    "print(metrics.classification_report(y_test, predictions))\n",
    "\n",
    "# getting the accuracy of the model\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print(f'accuracy score : {metrics.accuracy_score(y_test,predictions)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is far better than the Logistic Regression and Naive Bayes. we are able to classify the spam and there is little increase of accuracy.\n",
    "\n",
    "### Recall and Precision, F1 score also increased for the spam class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion Matrix\n",
      "       ham  spam\n",
      "ham   1507    86\n",
      "spam   137   109\n",
      "\n",
      "\n",
      "\n",
      " Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.92      0.95      0.93      1593\n",
      "        spam       0.56      0.44      0.49       246\n",
      "\n",
      "    accuracy                           0.88      1839\n",
      "   macro avg       0.74      0.69      0.71      1839\n",
      "weighted avg       0.87      0.88      0.87      1839\n",
      "\n",
      "\n",
      "\n",
      "accuracy score : 0.8787384448069603\n"
     ]
    }
   ],
   "source": [
    "# Applying the Decision tree for the classification\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_model = DecisionTreeClassifier()\n",
    "\n",
    "dt_model.fit(x_train,y_train)\n",
    "\n",
    "\n",
    "\n",
    "# performing the prediction\n",
    "\n",
    "predictions = dt_model.predict(x_test)\n",
    "\n",
    "# printing the confusion matrix\n",
    "print('confusion Matrix')\n",
    "print(pd.DataFrame(metrics.confusion_matrix(y_test, predictions), index = ['ham', 'spam'], columns = ['ham', 'spam']))\n",
    "\n",
    "# printing the recall and precision \n",
    "print('\\n\\n')\n",
    "print(' Classification Report')\n",
    "print(metrics.classification_report(y_test, predictions))\n",
    "\n",
    "# getting the accuracy of the model\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print(f'accuracy score : {metrics.accuracy_score(y_test,predictions)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is far better than all other models. we are able to classify the spam better.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion Matrix\n",
      "       ham  spam\n",
      "ham   1504    89\n",
      "spam   123   123\n",
      "\n",
      "\n",
      "\n",
      " Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.92      0.94      0.93      1593\n",
      "        spam       0.58      0.50      0.54       246\n",
      "\n",
      "    accuracy                           0.88      1839\n",
      "   macro avg       0.75      0.72      0.74      1839\n",
      "weighted avg       0.88      0.88      0.88      1839\n",
      "\n",
      "\n",
      "\n",
      "accuracy score : 0.8847199564980968\n"
     ]
    }
   ],
   "source": [
    "# Applying the Decision tree for the classification\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "rf_model.fit(x_train,y_train)\n",
    "\n",
    "\n",
    "\n",
    "# performing the prediction\n",
    "\n",
    "predictions = rf_model.predict(x_test)\n",
    "\n",
    "# printing the confusion matrix\n",
    "print('confusion Matrix')\n",
    "print(pd.DataFrame(metrics.confusion_matrix(y_test, predictions), index = ['ham', 'spam'], columns = ['ham', 'spam']))\n",
    "\n",
    "# printing the recall and precision \n",
    "print('\\n\\n')\n",
    "print(' Classification Report')\n",
    "print(metrics.classification_report(y_test, predictions))\n",
    "\n",
    "# getting the accuracy of the model\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print(f'accuracy score : {metrics.accuracy_score(y_test,predictions)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is better than Decision Tree as it is combination of decision trees. it is  able to classify the spam better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All the models taken so far. Not accounted the text into model. \n",
    "\n",
    "### i have taken only the length and punctation.\n",
    "\n",
    "### Building the Model on text might improve our accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape : (3733,)\n",
      "x_test shape: (1839,)\n"
     ]
    }
   ],
   "source": [
    "# creating the train and test split\n",
    "\n",
    "x= df['message']\n",
    "y= df['label']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_test, y_train, y_test = train_test_split(x,y,test_size = 0.33, random_state = 42)\n",
    "\n",
    "print(f'x_train.shape : {x_train.shape}')\n",
    "print(f'x_test shape: {x_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the TFdifvectrorizer ans linearsvc\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfdif',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('clf',\n",
       "                 LinearSVC(C=1.0, class_weight=None, dual=True,\n",
       "                           fit_intercept=True, intercept_scaling=1,\n",
       "                           loss='squared_hinge', max_iter=1000,\n",
       "                           multi_class='ovr', penalty='l2', random_state=None,\n",
       "                           tol=0.0001, verbose=0))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the Pipeline and training the model\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "text_clf= Pipeline([('tfdif',TfidfVectorizer()), ('clf',LinearSVC())])\n",
    "\n",
    "text_clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1586    7]\n",
      " [  12  234]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      1.00      0.99      1593\n",
      "        spam       0.97      0.95      0.96       246\n",
      "\n",
      "    accuracy                           0.99      1839\n",
      "   macro avg       0.98      0.97      0.98      1839\n",
      "weighted avg       0.99      0.99      0.99      1839\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predicting by using the classifier\n",
    "\n",
    "predictions = text_clf.predict(x_test)\n",
    "\n",
    "# getting the confusion matrix\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.confusion_matrix(y_test,predictions))\n",
    "\n",
    "# printing the classification report\n",
    "\n",
    "print(metrics.classification_report(y_test,predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1593    0]\n",
      " [  70  176]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.96      1.00      0.98      1593\n",
      "        spam       1.00      0.72      0.83       246\n",
      "\n",
      "    accuracy                           0.96      1839\n",
      "   macro avg       0.98      0.86      0.91      1839\n",
      "weighted avg       0.96      0.96      0.96      1839\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# creating the Pipeline and training the model\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "text_clf= Pipeline([('tfdif',TfidfVectorizer()), ('clf',MultinomialNB())])\n",
    "\n",
    "text_clf.fit(x_train, y_train)\n",
    "\n",
    "# predicting by using the classifier\n",
    "\n",
    "predictions = text_clf.predict(x_test)\n",
    "\n",
    "# getting the confusion matrix\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.confusion_matrix(y_test,predictions))\n",
    "\n",
    "# printing the classification report\n",
    "\n",
    "print(metrics.classification_report(y_test,predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1593    0]\n",
      " [  37  209]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      1.00      0.99      1593\n",
      "        spam       1.00      0.85      0.92       246\n",
      "\n",
      "    accuracy                           0.98      1839\n",
      "   macro avg       0.99      0.92      0.95      1839\n",
      "weighted avg       0.98      0.98      0.98      1839\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "# creating the Pipeline and training the model\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "text_clf= Pipeline([('tfdif',TfidfVectorizer()), ('clf',BernoulliNB())])\n",
    "\n",
    "text_clf.fit(x_train, y_train)\n",
    "\n",
    "# predicting by using the classifier\n",
    "\n",
    "predictions = text_clf.predict(x_test)\n",
    "\n",
    "# getting the confusion matrix\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.confusion_matrix(y_test,predictions))\n",
    "\n",
    "# printing the classification report\n",
    "\n",
    "print(metrics.classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1593    0]\n",
      " [  24  222]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      1.00      0.99      1593\n",
      "        spam       1.00      0.90      0.95       246\n",
      "\n",
      "    accuracy                           0.99      1839\n",
      "   macro avg       0.99      0.95      0.97      1839\n",
      "weighted avg       0.99      0.99      0.99      1839\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# creating the Pipeline and training the model\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "text_clf= Pipeline([('tfdif',TfidfVectorizer()), ('clf',SVC(degree=7))])\n",
    "\n",
    "text_clf.fit(x_train, y_train)\n",
    "\n",
    "# predicting by using the classifier\n",
    "\n",
    "predictions = text_clf.predict(x_test)\n",
    "\n",
    "# getting the confusion matrix\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.confusion_matrix(y_test,predictions))\n",
    "\n",
    "# printing the classification report\n",
    "\n",
    "print(metrics.classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The accuracy got impressively increased.  Out of all Model is giving the good accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['spam'], dtype=object)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking on how accurate the Model is \n",
    "\n",
    "text_clf.predict(['Congratuations.. congratulations... you won $100000 You won Congratulations..Congratulations!!..'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
